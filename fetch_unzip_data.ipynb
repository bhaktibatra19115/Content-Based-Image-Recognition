{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fetch_unzip_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWtmxWRUPmpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkwR8LLjeasZ",
        "colab_type": "text"
      },
      "source": [
        "Mount a directory\n",
        "\n",
        "Load and store pickle files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ileqchIkhg6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mountDir(dir, subdir = '', path = 'drive/My Drive/'):\n",
        "  \n",
        "    drive.mount('/content/drive')\n",
        "    print(os.getcwd())\n",
        "    if subdir == '':\n",
        "        os.chdir(path + dir)\n",
        "    else:\n",
        "        \n",
        "        os.chdir(path + dir + '/' + subdir)\n",
        "    print(os.getcwd())\n",
        "    # !ls -la\n",
        "\n",
        "def storeData(data, filename, ext = '.pkl'):\n",
        "\n",
        "    pickle.dump(data, open(filename + ext, 'wb') )  \n",
        "    print(filename + ext + ' saved!')\n",
        "\n",
        "def loadData(filename, ext = '.pkl'):     \n",
        "\n",
        "    filename += ext\n",
        "    data = pickle.load(open(filename, 'rb'))  \n",
        "    print(filename, ' loaded!')\n",
        "    \n",
        "    return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUEgGJ1qhvGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mountDir('IRProject')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u6ROa-1emdd",
        "colab_type": "text"
      },
      "source": [
        "Fetch data directly from link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IuBOy0aQfuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget http://vision.cs.utexas.edu/projects/finegrained/utzap50k/ut-zap50k-images.zip\n",
        "# !wget ftp://ftp.inrialpes.fr/pub/lear/douze/data/jpg1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiN3wylCSSrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %cd shoe_dataset\n",
        "# !unzip ut-zap50k-images.zip\n",
        "# %cd ..\n",
        "# %cd holiday_dataset\n",
        "# !tar -xvf jpg1.tar.gz -C jpg\n",
        "# %cd jpg\n",
        "# !ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QwJD3Lwy7OB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow # because cv2.imshow does'nt work in colab\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1pB_VmhyRcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_paths(title):\n",
        "    paths = []\n",
        "    for (dirpath, dirnames, filenames) in tqdm(os.walk(str(os.getcwd())+'/'+title+'/')):\n",
        "        for i in filenames:\n",
        "            paths.append(str(dirpath)+str(\"/\")+i)\n",
        "    return paths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_ks29iTykrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getPaths(load = True, shoe = True, holiday = True):\n",
        "    if load:\n",
        "        if shoe:\n",
        "            path_shoe = loadData('path_shoe', '.list')\n",
        "        if holiday:\n",
        "            path_holiday = loadData('path_holiday', '.list')\n",
        "    else:\n",
        "        if shoe:\n",
        "            path_shoe = build_paths('shoe_dataset')\n",
        "            storeData(path_shoe, 'path_shoe', '.list')\n",
        "        if holiday:            \n",
        "            path_holiday = build_paths('holiday_dataset')\n",
        "            storeData(path_holiday, 'path_holiday', '.list')\n",
        "    if shoe:\n",
        "        if holiday:\n",
        "            return path_shoe, path_holiday\n",
        "        return path_shoe\n",
        "    if holiday:\n",
        "        return path_holiday\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjyOOmLz3HcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getImages(load = True, shoe = True, holiday = True):\n",
        "    s_color = list()\n",
        "    s_grey = list()\n",
        "    h_color = list()\n",
        "    h_grey = list()\n",
        "    if load:\n",
        "        if shoe:\n",
        "            s_color = loadData('s_color_raw', '.list')\n",
        "            s_grey = loadData('s_grey_raw', '.list')\n",
        "        if holiday:\n",
        "            h_color = loadData('h_color_raw', '.list')\n",
        "            h_grey = loadData('h_grey_raw', '.list')\n",
        "    else:\n",
        "        if shoe:\n",
        "            for i in tqdm(range(len(path_shoe))):\n",
        "                img = cv2.imread(path_shoe[i])\n",
        "                s_color.append(img)\n",
        "                s_grey.append(cv2.cvtColor(img,cv2.COLOR_BGR2GRAY))\n",
        "            storeData(s_color, 's_color_raw', '.list')\n",
        "            storeData(s_grey, 's_grey_raw', '.list')\n",
        "        if holiday:            \n",
        "            for i in tqdm(range(len(path_holiday))):\n",
        "                img = cv2.imread(path_holiday[i])\n",
        "                r = 240/min(img.shape[:2])\n",
        "                img = cv2.resize(img, (0,0), fx=r, fy=r)\n",
        "                # cv2_imshow(img)\n",
        "                x = int((img.shape[0] - 240)/2)\n",
        "                y = int((img.shape[1] - 240)/2)\n",
        "                img = img[x:x+240,y:y+240]\n",
        "                filename = 'holiday_dataset2/' + path_holiday[i].split('/')[-1]\n",
        "                cv2.imwrite(filename, img)\n",
        "                h_color.append(img)\n",
        "                h_grey.append(cv2.cvtColor(img,cv2.COLOR_BGR2GRAY))\n",
        "            storeData(h_color, 'h_color_raw', '.list')\n",
        "            storeData(h_grey, 'h_grey_raw', '.list')\n",
        "    if shoe:\n",
        "        if holiday:\n",
        "            return s_color, s_grey, h_color, h_grey\n",
        "        return s_color, s_grey\n",
        "    if holiday:\n",
        "        return h_color, h_grey\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft-RpjSEDUfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WEy3VnsPxvn",
        "colab_type": "code",
        "outputId": "3ffa5326-4ffb-4dd2-ff40-0aaaf1010ed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# path_shoe, path_holiday = getPaths()\n",
        "s_color, s_grey, h_color, h_grey = getImages()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s_color_raw.list  loaded!\n",
            "s_grey_raw.list  loaded!\n",
            "h_color_raw.list  loaded!\n",
            "h_grey_raw.list  loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBSVX0QxiOw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df = pd.DataFrame({'path': path_shoe, 'color': s_color, 'grey': s_grey})\n",
        "# df.head()\n",
        "hdf = pd.DataFrame({'path': path_holiday, 'color': h_color, 'grey': h_grey})\n",
        "hdf.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ3-GaCvisxW",
        "colab_type": "text"
      },
      "source": [
        "Generate Feature Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVuNmVc5qjeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def histogram(image, bins = 10):\n",
        "    # convert the image to HSV color-space\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    # compute the color histogram\n",
        "    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
        "    # normalize the histogram\n",
        "    cv2.normalize(hist, hist)\n",
        "    # return the histogram\n",
        "    return hist.flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWAp0P1ebAad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hu_moments(image):\n",
        "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
        "    return feature"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfzaOchBYnMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mahotas\n",
        "import mahotas\n",
        "# feature-descriptor-2: Haralick Texture\n",
        "def haralick(image):\n",
        "    # convert the image to grayscale\n",
        "    # gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # compute the haralick texture feature vector\n",
        "    haralick = mahotas.features.haralick(image).mean(axis=0)\n",
        "    # return the result\n",
        "    return haralick"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SezY0fJxQJs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.feature import hog\n",
        "\n",
        "def hog_f(image):\n",
        "    fd, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True, multichannel=True)\n",
        "    return fd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYiuX0PEqjeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_image(img):\n",
        "    # img = cv2.imread(path)                 #original image\n",
        "    img2 = np.invert(img)                  #invert image\n",
        "    gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "    img2 = cv2.Canny(gray, threshold1=30, threshold2=100)    #edge detection\n",
        "    img2 = cv2.GaussianBlur(img2,(5,5),cv2.BORDER_DEFAULT) #gaussian blur \n",
        "    ret, img2 = cv2.threshold(img2, 1, 255, cv2.THRESH_BINARY)     #thresholding \n",
        "    img2 = cv2.adaptiveThreshold(img2 ,255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 255, 1)\n",
        "    img2 = np.invert(img2)\n",
        "    temp = tuple(img2 for i in range(3))\n",
        "    temp = np.dstack(temp)\n",
        "    image = cv2.subtract(img, temp)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j56sXz9VoU4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getFeatures(images, bins = 10):\n",
        "    hist = list()\n",
        "    hu_moment = list()\n",
        "    haral = list()\n",
        "    hogf = list()\n",
        "    orbf = list()\n",
        "    for i in tqdm(range(len(images))):\n",
        "        image = images[i]\n",
        "        grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        grey = cv2.GaussianBlur(grey,(5,5),cv2.BORDER_DEFAULT) #gaussian blur \n",
        "\n",
        "        hu_moment.append(hu_moments(grey))\n",
        "        haral.append(haralick(grey))\n",
        "\n",
        "        image = preprocess_image(images[i])\n",
        "\n",
        "        hist.append(histogram(image, bins))\n",
        "        hogf.append(hog_f(image))\n",
        "        orb = cv2.ORB_create()\n",
        "\n",
        "        # find the keypoints with ORB\n",
        "        kp = orb.detect(image,None)\n",
        "        # compute the descriptors with ORB\n",
        "        kp, des = orb.compute(image, kp)\n",
        "        if des is None:\n",
        "            orbf.append(np.array([[0]*32],dtype = 'uint8').flatten())\n",
        "        else:\n",
        "            orbf.append(des.flatten())       \n",
        "    storeData(hist, 'h_hist', '.list')\n",
        "    storeData(hogf, 'h_hog', '.list')\n",
        "    storeData(haral, 'h_haral', '.list')\n",
        "    storeData(hu_moment, 'h_hu', '.list')\n",
        "    storeData(orbf, 'h_orb', '.list')\n",
        "    return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KQCoLdjzIqs",
        "colab_type": "code",
        "outputId": "dc3942a2-1705-48a6-fa9f-33ed7a83a9bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "fl = getFeatures(hdf.color.values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 812/812 [03:26<00:00,  3.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "h_hist.list saved!\n",
            "h_hog.list saved!\n",
            "h_haral.list saved!\n",
            "h_hu.list saved!\n",
            "h_orb.list saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70ondsRnsdSW",
        "colab_type": "code",
        "outputId": "d83d5776-7554-45b6-f9df-ea214ce1b5d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "hist = loadData('s_hist', '.list')\n",
        "hogf = loadData('s_hog', '.list')\n",
        "haral = loadData('s_haral', '.list')\n",
        "hu_moment = loadData('s_hu', '.list')\n",
        "orbf = loadData('s_orb', '.list')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s_hist.list  loaded!\n",
            "s_hog.list  loaded!\n",
            "s_haral.list  loaded!\n",
            "s_hu.list  loaded!\n",
            "s_orb.list  loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VJyJWwBt9z6",
        "colab_type": "code",
        "outputId": "badce5b2-ccc8-416f-bfea-c2639e2a6a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(hist), type(hogf), type(haral), type(hu_moment), type(orbf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, list, list, list, list)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGyGi6DRQxkQ",
        "colab_type": "text"
      },
      "source": [
        "get histogram after segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE06MPeLudC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Histogram(image, mask):\n",
        "    hist = cv2.calcHist([image], [0, 1, 2], mask, (8, 12, 3), [0, 180, 0, 256, 0, 256])\n",
        "    hist = cv2.normalize(hist, hist).flatten()\n",
        "    return hist\n",
        "\n",
        "def get_feature(images):\n",
        "    featlist = list()\n",
        "    for i in tqdm(range(len(images))):\n",
        "        image = images[i]\n",
        "        # image = cv2.imread(path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "        feature = []\n",
        "        (h, w) = image.shape[:2]\n",
        "        (cX, cY) = (int(w * 0.5), int(h * 0.5))\n",
        "        segments = [(0, cX, 0, cY), (cX, w, 0, cY), (cX, w, cY, h),(0, cX, cY, h)]\n",
        "        (axesX, axesY) = (int(w * 0.75) // 2, int(h * 0.75) // 2)\n",
        "            \n",
        "        ellipMask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
        "        cornerMask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
        "        cv2.ellipse(ellipMask, (cX, cY), (axesX, axesY), 0, 0, 360, 255, -1)\n",
        "            \n",
        "        for (startX, endX, startY, endY) in segments:\n",
        "            cv2.rectangle(cornerMask, (startX, startY), (endX, endY), 255, -1)\n",
        "            cornerMask = cv2.subtract(cornerMask, ellipMask)\n",
        "            hist = Histogram(image, cornerMask)\n",
        "            feature.extend(hist)\n",
        "        hist = Histogram(image, ellipMask)\n",
        "        feature.extend(hist)\n",
        "        featlist.append(feature)\n",
        "    storeData(featlist, 'h_seghist', '.list')\n",
        "    return featlist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwP4wr1tupB4",
        "colab_type": "code",
        "outputId": "7f935aa9-1ba6-4da7-be21-6fc319b1694e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "seghist = get_feature(hdf.color.values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 812/812 [00:00<00:00, 1197.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "h_seghist.list saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDCcb8feSeS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = df.color.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAhrLfHCxb3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install PyWavelets\n",
        "import pywt\n",
        "# coeffs2 = pywt.dwt2(df.color.values[0], 'bior1.3')\n",
        "# LL, (LH, HL, HH) = coeffs2\n",
        "# images[0].shape\n",
        "# sta = np.hstack([LH, HL, HH])\n",
        "# # cv2_imshow(cv2.subtract(images[0], ))\n",
        "# images[0].shape, sta.shape, LH.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz-BzJUDgRju",
        "colab_type": "text"
      },
      "source": [
        "Holiday Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCd5iEkeJoNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import numpy as np\n",
        "# from numpy import linalg as LA\n",
        "# # from extract_cnn_vgg16_keras import VGGNet\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# from keras.preprocessing import image\n",
        "# from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# class VGGNet:\n",
        "#     def __init__(self):\n",
        "#         # weights: 'imagenet'\n",
        "#         # pooling: 'max' or 'avg'\n",
        "#         # input_shape: (width, height, 3), width and height should >= 48\n",
        "#         self.input_shape = (102, 136, 3)\n",
        "#         self.weight = 'imagenet'\n",
        "#         self.pooling = 'max'\n",
        "#         self.model = VGG16(weights = self.weight, input_shape = (self.input_shape[0], self.input_shape[1], self.input_shape[2]), pooling = self.pooling, include_top = False)\n",
        "#         self.model.predict(np.zeros((1, 102, 136 , 3)))\n",
        "\n",
        "#     '''\n",
        "#     Use vgg16 model to extract features\n",
        "#     Output normalized feature vector\n",
        "#     '''\n",
        "#     def extract_feat(self, img_path):\n",
        "#         # img=cv2.imread(img_path)\n",
        "#         img = image.load_img(img_path, target_size=(self.input_shape[0], self.input_shape[1]))\n",
        "#         img = image.img_to_array(img)\n",
        "#         # img=img.resize(224,224)\n",
        "#         img = np.expand_dims(img, axis=0)\n",
        "#         img = preprocess_input(img)\n",
        "#         feat = self.model.predict(img)\n",
        "#         norm_feat = feat[0]/LA.norm(feat[0])\n",
        "#         return norm_feat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fp08BsKLKYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model=VGGNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqAS1oJpKI5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"####features extraction process begins ####\")\n",
        "# features=[]\n",
        "# for i in tqdm(range(len(path))):\n",
        "  \n",
        "#   queryFeat = model.extract_feat(path[i])\n",
        "#   features.append(queryFeat)\n",
        "\n",
        "# print(\"####features created ####\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}